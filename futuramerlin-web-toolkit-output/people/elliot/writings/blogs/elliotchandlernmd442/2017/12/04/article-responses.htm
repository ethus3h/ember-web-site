<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <link href="/simple.css" rel="stylesheet" type="text/css"> <meta content="Ember" name="author"> <meta content="width=device-width,height=device-height,user-scalable=yes" name="viewport"> <meta name="generator" content="Futuramerlin Web Toolkit 2.3.75"> <title>Article responses: 2017 Dec. 04 — Elliot's NMD442 Blog! &mdash; Ember</title> </head> <body class="lessChrome">  <main> <h1>Article responses: 2017 Dec. 04 — Elliot's NMD442 Blog!</h1>  <p><big><a href="../../.."> « Back to blog index</a></big></p><nav id="toc"><h2>Table of Contents</h2> <ol><li><a href="#Response_to_.22">Response to "When It Comes to UX Design, Simplicity Is Overrated"</a></li> <li><a href="#Response_to_.22_1">Response to "Good design doesn't make people happy."</a></li> <li><a href="#Response_to_.22_2">Response to "Creating a Chatbot: A UX Designer’s Firsthand Experience"</a></li> </ol> </nav> <h2 id="Response_to_.22">Response to "<a href="https://www.fastcodesign.com/3048139/what-is-zero-ui-and-why-is-it-crucial-to-the-future-of-design">When It Comes to UX Design, Simplicity Is Overrated</a>"</h2> <p><em>Article by John Brownlee: 2 July 2015, in </em>Co.Design</p> <p>In this interview, the concept of "Zero UI" is introduced, referring to the user interfaces of Internet of Things equipment and non-touchscreen-driven user interfaces, particularly interfaces that deal with non-two-dimensional interaction. This type of user interface presents unusual challenges to designers. This is an area of ongoing research. Similarly to the chatbot interface discussed below, however, I am inclined towards skepticism regarding how well this type of technology can be gotten to work, especially within the forseeable future. That is because these technologies run up against edge cases that cannot be easily disambiguated, such as a hand gesture while talking as opposed to gesture towards a kinetic user interface. I certainly grant that innovations or refinements in the field will solve these issues, but I do hope that big clunky IBM-style keyboards with pointing sticks remain for a while yet, since the flat "chiclet" style keyboards, with their reduced key travel and non-contoured keytops, really <em>are</em> much less pleasant to use, and despite that they have become nearly ubiquitous in the interest of fashion and what is perceived as "elegant" appearance. The utility of a functional, practical interface, though, entirely outweighs such concerns for me, and indeed, such practical things really do bear something of an elegant aesthetic within their utility. Consequently, my interest in the capabilities of these innovative user interfaces is marred by the worry that current interfaces that work well will be disregarded in the design of future technology, resulting in a degraded experience in one regard for users who desire a traditional, non-fashion-fettered interfaces to avoid a degraded experience in that other regard.</p> <h2 id="Response_to_.22_1">Response to "<a href="https://blog.prototypr.io/good-design-doesnt-make-people-happy-a90e2f033ba0">Good design doesn't make people happy.</a>"</h2> <p><em>Article by John Warren Hanawalt: 27 November 2017, in </em>Prototypr</p> <p>This was an interesting hypothesis. The author writes: "If you can learn to be comfortable with" ... "negative emotions during the project, you can deliver more meaningful happiness at the end." ... "Until then, you’re all just working together." How is participating in a working relationship where one has to deal with negative emotions "working together", or productive, healthy, and professional at all? Respect and civility are fundamental to effective collaboration. If neither client nor contractor are able to step away from a situation as required to remain objective about it, which is where negative emotions in this context come from, the working relationship has <em>already</em> failed: when frustration or anger starts to take over, it's critical to try to use friendly, clear communication to find a consensus regarding the issue. While stepping back like this can be very difficult to do, due to the stubbornness of human emotion, it is a critical life skill to have in order to not bring unhappiness to yourself and others. Developing this skill is a challenge that I am still trying to work through, but to the extent that I have learned it, it has served me well, and I suspect it will you as well. Wholeheartedly endorsed. Anyway, to get back to the point, the article makes a very good point about client happiness not being a particularly useful target metric for a contract project, and the very good point that overworking one's self outside of what is contracted to fix a problem caused by the client (a result of one's sense of service or duty) is unproductive and unhealthy. However, I do disagree with the implication that pushing ahead with a project that has become negative is a good way to succeed at a contract. Rather, staying in a state like that in a professional relationship is dangerous and unhealthy.</p> <h2 id="Response_to_.22_2">Response to "<a href="https://uxmag.com/creating-a-chatbot">Creating a Chatbot: A UX Designer’s Firsthand Experience</a>"</h2> <p><em>Article by Scott Milburn: 7 November 2017, in </em>Wired</p> <p>This article seems overly optimistic to me. While artificial intelligence is certainly progressing rapidly, in my experience chatbots, at least the simple ones that are commonly available, are nowhere near capable of having a meaningful, effective conversation. Considering that Google's and Apple's conversational interfaces are quite prone to misinterpreting queries, and they only attempt to provide basic information with brief context (such as based on other recent queries), I think that a chatbot that would be able to actually provide sufficiently nuanced responses to be conversational is quite a ways in the future. The idea of a bot to respond to a nagging parent proposed in the article would need such nuance to be useful, and would need a contextual understanding of the person whose role it is filling and of that person's life. The sort of responses shown in the article, I think, would be more likely to have the parent wondering what sort of drugs their kid is on than to reassure them, simply because of the repetitiveness and frequent nonsequiturs. The article suggests that only further data training is necessary, but I disagree — a system like this falls apart as soon as it is asked to reason about something outside of its experience, or with more complexity software traditionally does. For instance, consider the situation where Sally's parent asked, "What would you like for supper tonight?" and Sally's bot replied "Pulled pork, thanks!", and then the parent wrote back saying "Don't forget Bob will be over... ;)". Sally would know that Bob is a vegetarian, and wouldn't like pulled pork. A chatbot would run into two major roadblocks in handling that scenario. First, it would have to understand that this response is requesting an amended response to the question about food on the basis of this new information. Second, it would have to understand that Bob is a vegetarian, and know that Bob being a vegetarian indicates that a non-meat food that Sally likes is the appropriate response. While that sort of reasoning is pretty much subconscious and instantaneous for humans, it is very difficult for computers (just as doing mathematical operations on large amounts of data is very difficult for humans, but trivial for computers).</p> <footer class="nav-links"> <div class="nav-previous"> <a href="../../../2017/11/28/1-on-demand-snow-plowing.htm" rel="prev"><span class="meta-nav">&larr; Previous post: </span>On-Demand Snow Plowing</a> </div> <div class="nav-next"> <a href="../../../2017/12/07/article-responses.htm" rel="next"><span class="meta-nav">Next post: </span>Article responses: 2017 Dec. 07<span class="meta-nav"> &rarr;</span></a> </div> </footer> </main> </body> </html>